{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ee0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3025e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads Glove embedding file to embed input words\n",
    "def loadEmbedding(embeddingFile, embed_dim=50, vocab_size=50000):\n",
    "    vocabulary = []\n",
    "    embeddingMatrix = np.zeros((vocab_size, embed_dim))\n",
    "    with open(embeddingFile, 'r', encoding='utf-8') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count+2 >= vocab_size:\n",
    "                break\n",
    "            word, vect = line.split(maxsplit=1)\n",
    "            vect = np.fromstring(vect, \"f\", sep=\" \")\n",
    "            vocabulary.append(word)\n",
    "            embeddingMatrix[count+2][:] = vect\n",
    "    return vocabulary, embeddingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b9d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_tokens= vocabSize, embedding_dim=output size (50)\n",
    "\n",
    "#generates untrained RNN that used GloVe embedding and a LSTM layer\n",
    "def generateRNN1(vocabulary, embeddingMatrix, max_len=20, embeddingSize=50, vocabSize=50000):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "    model.add(keras.layers.TextVectorization(max_tokens=vocabSize, output_sequence_length=max_len, vocabulary=vocabulary))\n",
    "    model.add(keras.layers.Embedding(input_dim=vocabSize, output_dim=embeddingSize, embeddings_initializer=keras.initializers.Constant(embeddingMatrix), trainable=False))\n",
    "    model.add(keras.layers.LSTM(256))\n",
    "    model.add(keras.layers.Dense(16))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#generates untrained RNN that uses GloVe embedding and GRU layer\n",
    "def generateRNN2(vocabulary, embeddingMatrix, max_len=20, embeddingSize=50, vocabSize=50000):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "    model.add(keras.layers.TextVectorization(max_tokens=vocabSize, output_sequence_length=max_len, vocabulary=vocabulary))\n",
    "    model.add(keras.layers.Embedding(input_dim=vocabSize, output_dim=embeddingSize, embeddings_initializer=keras.initializers.Constant(embeddingMatrix), trainable=False))\n",
    "    model.add(keras.layers.GRU(256))\n",
    "    model.add(keras.layers.Dense(16))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#generates untrained RNN that uses Glove embedding and 2 LSTM layers\n",
    "def generateRNN3(vocabulary, embeddingMatrix, max_len=20, embeddingSize=50, vocabSize=50000):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "    model.add(keras.layers.TextVectorization(max_tokens=vocabSize, output_sequence_length=max_len, vocabulary=vocabulary))\n",
    "    model.add(keras.layers.Embedding(input_dim=vocabSize, output_dim=embeddingSize, embeddings_initializer=keras.initializers.Constant(embeddingMatrix), trainable=False))\n",
    "    model.add(keras.layers.LSTM(256, return_sequences=True))\n",
    "    model.add(keras.layers.LSTM(64))\n",
    "    model.add(keras.layers.Dense(16))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de422d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots loss value and the accuracy for the two different models\n",
    "def draw_loss(history1):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    #defines and labels the axes\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    \n",
    "    #plots loss on x axis #1 and accuracy on x axis #2\n",
    "    ax1.plot(history1.history['loss'], 'b-', label= \"model1-Loss\")\n",
    "    ax2.plot(history1.history['acc'], 'b:', label=\"model1-Accuracy\")\n",
    "    ax1.legend(bbox_to_anchor=(1.1, 0), loc=\"lower left\")\n",
    "    ax2.legend(bbox_to_anchor=(1.1, 1), loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08361145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "filePath = 'training.1600000.processed.noemoticon.csv'\n",
    "data = pd.read_csv(filePath, names=['sentiment', 'del1', 'del2', 'del3', 'del4', 'text'], usecols=['sentiment', 'text'], encoding='latin-1')\n",
    "\n",
    "# gets labels and features (text) from dataset\n",
    "labels = data['sentiment'].replace(to_replace=4, value=1)\n",
    "features = data['text']\n",
    "\n",
    "# splits dataset into training (80%), testing (10%), and validation (10%)\n",
    "trainingFeatures, testingFeatures, trainingLabels, testingLabels = train_test_split(features, labels, test_size=.2)\n",
    "validationFeatures, testingFeatures, validationLabels, testingLabels = train_test_split(testingFeatures, testingLabels, test_size=.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb75fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads GloVe embedding file\n",
    "localPath = 'glove.6B.50d.txt'\n",
    "vocab, embeddingMatrix = loadEmbedding(localPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead63ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 20)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 20, 50)            2500000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               314368    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                4112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,818,497\n",
      "Trainable params: 318,497\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 452s 90ms/step - loss: 0.5044 - binary_accuracy: 0.7493 - val_loss: 0.4649 - val_binary_accuracy: 0.7777\n",
      "Epoch 2/5\n",
      "2203/5000 [============>.................] - ETA: 4:14 - loss: 0.4568 - binary_accuracy: 0.7816"
     ]
    }
   ],
   "source": [
    "# generates and trains RNN model1\n",
    "model1 = generateRNN1(vocab, embeddingMatrix)\n",
    "history1 = model1.fit(trainingFeatures, trainingLabels,  batch_size=256, epochs=5, validation_data=(validationFeatures, validationLabels))\n",
    "model1.save('savedModels/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b0503f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_18 (Text  (None, 20)               0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_18 (Embedding)    (None, 20, 50)            2500000   \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 256)               236544    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                4112      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,740,673\n",
      "Trainable params: 240,673\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n",
      "1250/1250 [==============================] - 189s 150ms/step - loss: 0.5428 - binary_accuracy: 0.7184 - val_loss: 0.4999 - val_binary_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "# generates and trains RNN model2\n",
    "model2 = generateRNN2(vocab, embeddingMatrix)\n",
    "history2 = model2.fit(trainingFeatures, trainingLabels,  batch_size=256, epochs=5, validation_data=(validationFeatures, validationLabels))\n",
    "model2.save('savedModels/model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ca9100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_17 (Text  (None, 20)               0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_17 (Embedding)    (None, 20, 50)            2500000   \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 20, 256)           314368    \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 64)                82176     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,897,601\n",
      "Trainable params: 397,601\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n",
      "625/625 [==============================] - 183s 288ms/step - loss: 0.5759 - binary_accuracy: 0.6944 - val_loss: 0.5357 - val_binary_accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "# generates and trains RNN model3\n",
    "model3 = generateRNN3(vocab, embeddingMatrix)\n",
    "history3 = model3.fit(trainingFeatures, trainingLabels,  batch_size=256, epochs=5, validation_data=(validationFeatures, validationLabels))\n",
    "model3.save('savedModels/model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 accuracy1= model1.evaluate(testingFeatures, testingLabels)\n",
    "\n",
    "print(\"Model 1:\")\n",
    "print(\"Loss: \", loss1)\n",
    "print(\"Accuracy: \", accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2, accuracy2 = model2.evaluate(testingFeatures, testingLabels)\n",
    "\n",
    "print(\"Model 2:\")\n",
    "print(\"Loss: \", loss2)\n",
    "print(\"Accuracy: \", accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f24144",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss3, accuracy3 = model3.evaluate(testingFeatures, testingLabels)\n",
    "\n",
    "print(\"Model 3:\")\n",
    "print(\"Loss: \", loss3)\n",
    "print(\"Accuracy: \", accuracy3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
