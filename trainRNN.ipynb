{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ee0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3025e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads Glove embedding file to embed input words\n",
    "def loadEmbedding(embeddingFile, embed_dim=50, vocab_size=50000):\n",
    "    vocabulary = []\n",
    "    embeddingMatrix = np.zeros((vocab_size, embed_dim))\n",
    "    with open(embeddingFile, 'r', encoding='utf-8') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count+2 >= vocab_size:\n",
    "                break\n",
    "            word, vect = line.split(maxsplit=1)\n",
    "            vect = np.fromstring(vect, \"f\", sep=\" \")\n",
    "            vocabulary.append(word)\n",
    "            embeddingMatrix[count+2][:] = vect\n",
    "    return vocabulary, embeddingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b9d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_tokens= vocabSize, embedding_dim=output size (50)\n",
    "\n",
    "#generates untrained RNN that used GloVe embedding and a LSTM layer\n",
    "def generateRNN1(vocabulary, embeddingMatrix, max_len=20, embeddingSize=50, vocabSize=50000):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "    model.add(keras.layers.TextVectorization(max_tokens=vocabSize, output_sequence_length=max_len, vocabulary=vocabulary))\n",
    "    model.add(keras.layers.Embedding(input_dim=vocabSize, output_dim=embeddingSize, embeddings_initializer=keras.initializers.Constant(embeddingMatrix), trainable=False))\n",
    "    model.add(keras.layers.LSTM(256))\n",
    "    model.add(keras.layers.Dense(16))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#generates untrained RNN that uses GloVe embedding and GRU layer\n",
    "def generateRNN2(vocabulary, embeddingMatrix, max_len=20, embeddingSize=50, vocabSize=50000):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "    model.add(keras.layers.TextVectorization(max_tokens=vocabSize, output_sequence_length=max_len, vocabulary=vocabulary))\n",
    "    model.add(keras.layers.Embedding(input_dim=vocabSize, output_dim=embeddingSize, embeddings_initializer=keras.initializers.Constant(embeddingMatrix), trainable=False))\n",
    "    model.add(keras.layers.GRU(256))\n",
    "    model.add(keras.layers.Dense(16))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#generates untrained RNN that uses Glove embedding and 2 LSTM layers\n",
    "def generateRNN3(vocabulary, embeddingMatrix, max_len=20, embeddingSize=50, vocabSize=50000):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(1,), dtype=tf.string))\n",
    "    model.add(keras.layers.TextVectorization(max_tokens=vocabSize, output_sequence_length=max_len, vocabulary=vocabulary))\n",
    "    model.add(keras.layers.Embedding(input_dim=vocabSize, output_dim=embeddingSize, embeddings_initializer=keras.initializers.Constant(embeddingMatrix), trainable=False))\n",
    "    model.add(keras.layers.LSTM(256, return_sequences=True))\n",
    "    model.add(keras.layers.LSTM(64))\n",
    "    model.add(keras.layers.Dense(16))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de422d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots loss value and the accuracy for the two different models\n",
    "def draw_loss(history1):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    #defines and labels the axes\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    \n",
    "    #plots loss on x axis #1 and accuracy on x axis #2\n",
    "    ax1.plot(history1.history['loss'], 'b-', label= \"model1-Loss\")\n",
    "    ax2.plot(history1.history['acc'], 'b:', label=\"model1-Accuracy\")\n",
    "    ax1.legend(bbox_to_anchor=(1.1, 0), loc=\"lower left\")\n",
    "    ax2.legend(bbox_to_anchor=(1.1, 1), loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08361145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "filePath = 'training.1600000.processed.noemoticon.csv'\n",
    "data = pd.read_csv(filePath, names=['sentiment', 'del1', 'del2', 'del3', 'del4', 'text'], usecols=['sentiment', 'text'], encoding='latin-1')\n",
    "\n",
    "# gets labels and features (text) from dataset\n",
    "labels = data['sentiment'].replace(to_replace=4, value=1)\n",
    "features = data['text']\n",
    "\n",
    "# splits dataset into training (80%), testing (10%), and validation (10%)\n",
    "trainingFeatures, testingFeatures, trainingLabels, testingLabels = train_test_split(features, labels, test_size=.2)\n",
    "validationFeatures, testingFeatures, validationLabels, testingLabels = train_test_split(testingFeatures, testingLabels, test_size=.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb75fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads GloVe embedding file\n",
    "localPath = 'glove.6B.50d.txt'\n",
    "vocab, embeddingMatrix = loadEmbedding(localPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead63ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 20)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 20, 50)            2500000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               314368    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                4112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,818,497\n",
      "Trainable params: 318,497\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 452s 90ms/step - loss: 0.5044 - binary_accuracy: 0.7493 - val_loss: 0.4649 - val_binary_accuracy: 0.7777\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 474s 95ms/step - loss: 0.4506 - binary_accuracy: 0.7858 - val_loss: 0.4385 - val_binary_accuracy: 0.7918\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 478s 96ms/step - loss: 0.4281 - binary_accuracy: 0.7992 - val_loss: 0.4296 - val_binary_accuracy: 0.7991\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 471s 94ms/step - loss: 0.4120 - binary_accuracy: 0.8088 - val_loss: 0.4229 - val_binary_accuracy: 0.8028\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 465s 93ms/step - loss: 0.3985 - binary_accuracy: 0.8162 - val_loss: 0.4208 - val_binary_accuracy: 0.8038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: savedModels/model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: savedModels/model1\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001863C934820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# generates and trains RNN model1\n",
    "model1 = generateRNN1(vocab, embeddingMatrix)\n",
    "history1 = model1.fit(trainingFeatures, trainingLabels,  batch_size=256, epochs=5, validation_data=(validationFeatures, validationLabels))\n",
    "model1.save('savedModels/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0503f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, 20)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 20, 50)            2500000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 256)               236544    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,740,673\n",
      "Trainable params: 240,673\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 347s 69ms/step - loss: 0.4960 - binary_accuracy: 0.7544 - val_loss: 0.4570 - val_binary_accuracy: 0.7804\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 354s 71ms/step - loss: 0.4453 - binary_accuracy: 0.7884 - val_loss: 0.4366 - val_binary_accuracy: 0.7937\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 345s 69ms/step - loss: 0.4251 - binary_accuracy: 0.8006 - val_loss: 0.4339 - val_binary_accuracy: 0.7957\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 351s 70ms/step - loss: 0.4107 - binary_accuracy: 0.8088 - val_loss: 0.4347 - val_binary_accuracy: 0.7951\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 350s 70ms/step - loss: 0.3980 - binary_accuracy: 0.8163 - val_loss: 0.4345 - val_binary_accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: savedModels/model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: savedModels/model2\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000018642E9E550> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# generates and trains RNN model2\n",
    "model2 = generateRNN2(vocab, embeddingMatrix)\n",
    "history2 = model2.fit(trainingFeatures, trainingLabels,  batch_size=256, epochs=5, validation_data=(validationFeatures, validationLabels))\n",
    "model2.save('savedModels/model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca9100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, 20)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 20, 50)            2500000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20, 256)           314368    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                82176     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,897,601\n",
      "Trainable params: 397,601\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 632s 126ms/step - loss: 0.5024 - binary_accuracy: 0.7507 - val_loss: 0.4597 - val_binary_accuracy: 0.7792\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 623s 125ms/step - loss: 0.4471 - binary_accuracy: 0.7878 - val_loss: 0.4399 - val_binary_accuracy: 0.7929\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 613s 123ms/step - loss: 0.4238 - binary_accuracy: 0.8018 - val_loss: 0.4237 - val_binary_accuracy: 0.8024\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 605s 121ms/step - loss: 0.4073 - binary_accuracy: 0.8115 - val_loss: 0.4186 - val_binary_accuracy: 0.8048\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 606s 121ms/step - loss: 0.3928 - binary_accuracy: 0.8195 - val_loss: 0.4209 - val_binary_accuracy: 0.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: savedModels/model3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: savedModels/model3\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000186455D4DF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018641C91BB0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# generates and trains RNN model3\n",
    "model3 = generateRNN3(vocab, embeddingMatrix)\n",
    "history3 = model3.fit(trainingFeatures, trainingLabels,  batch_size=256, epochs=5, validation_data=(validationFeatures, validationLabels))\n",
    "model3.save('savedModels/model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a4559c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 125s 25ms/step - loss: 0.4221 - binary_accuracy: 0.8038\n",
      "Model 1:\n",
      "Loss:  0.4220907688140869\n",
      "Accuracy:  0.8038374781608582\n"
     ]
    }
   ],
   "source": [
    "loss1, accuracy1= model1.evaluate(testingFeatures, testingLabels)\n",
    "\n",
    "print(\"Model 1:\")\n",
    "print(\"Loss: \", loss1)\n",
    "print(\"Accuracy: \", accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d064b361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 98s 20ms/step - loss: 0.4346 - binary_accuracy: 0.7972\n",
      "Model 2:\n",
      "Loss:  0.4345569312572479\n",
      "Accuracy:  0.7971875071525574\n"
     ]
    }
   ],
   "source": [
    "loss2, accuracy2 = model2.evaluate(testingFeatures, testingLabels)\n",
    "\n",
    "print(\"Model 2:\")\n",
    "print(\"Loss: \", loss2)\n",
    "print(\"Accuracy: \", accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f24144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 135s 27ms/step - loss: 0.4224 - binary_accuracy: 0.8049\n",
      "Model 3:\n",
      "Loss:  0.42237427830696106\n",
      "Accuracy:  0.8048562407493591\n"
     ]
    }
   ],
   "source": [
    "loss3, accuracy3 = model3.evaluate(testingFeatures, testingLabels)\n",
    "\n",
    "print(\"Model 3:\")\n",
    "print(\"Loss: \", loss3)\n",
    "print(\"Accuracy: \", accuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33267c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
